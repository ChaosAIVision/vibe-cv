ðŸ§‘â€ðŸ’» AI/GenAI Engineer Intern
Email: [áº¨n] | LinkedIn: [áº¨n] | Mobile: (+84) [áº¨n] | Github: [áº¨n]

ðŸŽ“ EDUCATION
Hanoi University of Civil Engineering | Ha Noi, Viet Nam

Major: BSc of Computer Science | CPA: 3.21 | Sep 2022 - Jun 2026(Expected)

- Awarded Scholarships for Good Academic Achievements | 2023, 2024

ðŸ› ï¸ SKILLS
Programming Languages: Python, SQL

AI frameworks: Pytorch, (Sentence)Transformers, PEFT, Langchain, Langgraph, Unsloth

Web frameworks: FastAPI

Database: PostgreSQL, Pinecone

Tools: Git, Docker, Linux, GCP Vertex AI

Languages: Vietnamese (native), English (B2)

ðŸ“ PROJECTS
â€¢ Image to LaTeX [Github]
[Python, Pytorch, FastAPI, ...]

XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c sÃ¢u tá»« chuáº©n bá»‹ dá»¯ liá»‡u, huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  triá»ƒn khai qua API Ä‘á»ƒ chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh cÃ´ng thá»©c toÃ¡n há»c thÃ nh mÃ£ LaTeX.

Triá»ƒn khai mÃ´ hÃ¬nh káº¿t há»£p Resnet-18 backbone Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng hÃ¬nh áº£nh vá»›i má»™t Transformer decoder cho viá»‡c táº¡o chuá»—i.

Huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u IM2LATEX-100K, tÆ°Æ¡ng á»©ng vá»›i mÃ£ LaTeX cho má»—i hÃ¬nh áº£nh.

Káº¿t quáº£: BLEU-1: 81.06%, exact match (EM): 25.15%, character error rate (CER): 14.28%, edit distance (ED): 15.29 trÃªn táº­p kiá»ƒm thá»­.

â€¢ RAG-based Knowledge Assistant [Github]
[Python, Langchain, OpenAI, Cohere, Streamlit, Postgres+pgvector, ...]

XÃ¢y dá»±ng má»™t há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) Ä‘á»ƒ truy váº¥n dá»¯ liá»‡u tá»« cáº£ cÃ¡c tÃ i liá»‡u cá»¥c bá»™ vÃ  URL, tÄƒng cÆ°á»ng kháº£ nÄƒng truy cáº­p linh hoáº¡t.

Triá»ƒn khai kiáº¿n trÃºc hai giai Ä‘oáº¡n: tÃ¬m kiáº¿m ngá»¯ nghÄ©a (semantic search) + Xáº¿p háº¡ng láº¡i (Cohere reranking), cáº£i thiá»‡n Ä‘á»™ liÃªn quan cá»§a cÃ¢u tráº£ lá»i dá»±a trÃªn tÃ¬m kiáº¿m vector.

Kiáº¿n trÃºc Ä‘áº§u cuá»‘i bao gá»“m: phÃ¢n tÃ­ch tÃ i liá»‡u (Docling) vÃ  trÃ­ch xuáº¥t URL (trafilatura), chia Ä‘oáº¡n vÄƒn báº£n Ä‘á»‡ quy, táº¡o embedding (OpenAI embedding generation), vÃ  lÆ°u trá»¯ trong PostgreSQL+pgvector.

PhÃ¡t triá»ƒn má»™t giao diá»‡n thÃ¢n thiá»‡n vá»›i ngÆ°á»i dÃ¹ng báº±ng Streamlit vÃ  Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i báº±ng Docker.

â€¢ Fine-tuning Gemma Models for Medical QAs and Retrieval [Github]
[Python, Transformers, PEFT, Unsloth, WanDB, ...]

LoRA fine-tuned embedding-Gemma-300m embedding model trÃªn táº­p dá»¯ liá»‡u viet-med-qa (~10k rows) [Huggingface].

Káº¿t quáº£: accuracy@1: 44% -> 85%, ndcg@10: 0.60 -> 0.92, mrr@10: 0.55 -> 0.89...

Supervised fine-tuned gemma-3b-it model trÃªn táº­p dá»¯ liá»‡u VietnameseHealth-QA-dataset (~16k rows) [Huggingface].